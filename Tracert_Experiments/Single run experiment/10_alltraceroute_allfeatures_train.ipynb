{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import warnings\n",
    "import platform\n",
    "import sys\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Making the plots standard \n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-14.2.1-arm64-arm-64bit\n",
      "Python 3.10.11 (main, Apr  7 2023, 07:24:53) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "Pandas 2.0.1\n",
      "Scikit-Learn 1.4.0\n"
     ]
    }
   ],
   "source": [
    "#Hardware and software details \n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the pickled dataframes you will be using for the experiments\n",
    "latency_df = pd.read_pickle('latency_withprobe.pickle')\n",
    "\n",
    "#remove the null values from the experiment_df \n",
    "nan_rows = latency_df[latency_df['last_rtt'].isnull()]\n",
    "latency_df = latency_df.dropna(subset=['last_rtt'])\n",
    "\n",
    "len(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238890"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove indexes where last_rtt is greater than 100ms \n",
    "latency_df = latency_df[latency_df['last_rtt'] < 100]\n",
    "len(latency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fw', 'lts', 'proto', 'af', 'size', 'paris_id', 'prb_id', 'msm_name',\n",
       "       'destination_ip_responded', 'dst_id', 'src_names', 'distance',\n",
       "       'source_longitude', 'source_latitude', 'destination_longitude',\n",
       "       'destination_latitude', 'date', 'last_rtt', 'hop_count', 'ASN_source',\n",
       "       'CountryCode_source', 'source_status', 'Anchor_source',\n",
       "       'Latitude_source', 'Longitude_source', 'Public_source',\n",
       "       'Uptime(days)_source', 'ASN_destination', 'CountryCode_destination',\n",
       "       'destination_status', 'Anchor_destination', 'Latitude_destination',\n",
       "       'Longitude_destination', 'Public_destination',\n",
       "       'Uptime(days)_destination', 'day_of_week', 'hour_of_day',\n",
       "       'minute_of_hour', 'source_status_change(days)',\n",
       "       'destination_status_change(days)', 'norm_timestamp',\n",
       "       'norm_storedtimestamp', 'src_Octet1', 'src_Octet2', 'src_Octet3',\n",
       "       'src_Octet4', 'src_Mask', 'dst_Octet1', 'dst_Octet2', 'dst_Octet3',\n",
       "       'dst_Octet4', 'dst_Mask'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = latency_df.copy()\n",
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before applying models randomise selection of training and test data\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "test_indices = []\n",
    "train_indices = []\n",
    "        \n",
    "array1 = model_df['prb_id'].unique()\n",
    "array2 = model_df['dst_id'].unique()\n",
    "\n",
    "# Creating all possible pairs\n",
    "pairs = list(itertools.product(array1, array2))\n",
    "\n",
    "# Randomly selecting 10 pairs\n",
    "selected_pairs = random.sample(pairs, 10)\n",
    "\n",
    "# Removing selected pairs from the original list\n",
    "for pair in selected_pairs:\n",
    "    pairs.remove(pair)\n",
    "\n",
    "# Creating separate lists\n",
    "selected_list = selected_pairs\n",
    "remaining_list = pairs\n",
    "\n",
    "train_dfs = []\n",
    "for i,k in remaining_list:\n",
    "    temp_df = model_df.loc[(model_df['prb_id'] == i) & (model_df['dst_id'] == k)]\n",
    "            \n",
    "    # Append the piece to the selected data\n",
    "    train_dfs.append(temp_df)\n",
    "            \n",
    "    train_df = pd.concat(train_dfs)\n",
    "        \n",
    "test_dfs = []\n",
    "for i,k in selected_list:\n",
    "    temp_df = model_df.loc[(model_df['prb_id'] == i) & (model_df['dst_id'] == k)]\n",
    "            \n",
    "    # Append the piece to the selected data\n",
    "    test_dfs.append(temp_df)\n",
    "\n",
    "    test_df = pd.concat(train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15118, 15632),\n",
       " (55787, 15632),\n",
       " (51265, 1004200),\n",
       " (51265, 30381),\n",
       " (55787, 14866),\n",
       " (51265, 26072),\n",
       " (55787, 1004200),\n",
       " (61357, 1004200),\n",
       " (51265, 15632),\n",
       " (15118, 1004200)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15118, 14866),\n",
       " (15118, 30381),\n",
       " (15118, 26072),\n",
       " (33627, 14866),\n",
       " (33627, 1004200),\n",
       " (33627, 15632),\n",
       " (33627, 30381),\n",
       " (33627, 26072),\n",
       " (51265, 14866),\n",
       " (55787, 30381),\n",
       " (55787, 26072),\n",
       " (61357, 14866),\n",
       " (61357, 15632),\n",
       " (61357, 30381),\n",
       " (61357, 26072)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the rtt values \n",
    "trainrtt_mean = train_df['last_rtt'].mean()\n",
    "trainrtt_std = train_df['last_rtt'].std()\n",
    "train_df['normalizzed_rtt'] = (train_df['last_rtt'] - trainrtt_mean) / trainrtt_std\n",
    "\n",
    "# normalize the 'distance' column\n",
    "traindist_mean = train_df['distance'].mean()\n",
    "traindist_std = train_df['distance'].std()\n",
    "train_df['normalizzed_distance'] = (train_df['distance'] - traindist_mean) / traindist_std\n",
    "        \n",
    "#normalise the test rtt values \n",
    "test_df['normalizzed_rtt'] = (test_df['last_rtt'] - trainrtt_mean) / trainrtt_std\n",
    "\n",
    "# normalize the 'distance' column for the test set \n",
    "test_df['normalizzed_distance'] = (test_df['distance'] - traindist_mean) / traindist_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#check for nan values in normalised rtt and distance\n",
    "nan_train = train_df[train_df['normalizzed_rtt'].isnull()]\n",
    "nan_test = test_df[test_df['normalizzed_rtt'].isnull()]\n",
    "print(len(nan_train),len(nan_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the train and test dataframes\n",
    "train_df.to_pickle('train_df.pickle')\n",
    "test_df.to_pickle('test_df.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
