{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder named 'pickles' (you can change the folder name as needed)\n",
    "import os \n",
    "folder_name = 'train_test_pickles'\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import warnings\n",
    "import platform\n",
    "import sys\n",
    "import itertools\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_df = pd.read_pickle('latency_withprobe.pickle')\n",
    "\n",
    "#remove the null values from the experiment_df \n",
    "nan_rows = latency_df[latency_df['last_rtt'].isnull()]\n",
    "latency_df = latency_df.dropna(subset=['last_rtt'])\n",
    "\n",
    "model_df = latency_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 completed.\n",
      "Iteration 2 completed.\n",
      "Iteration 3 completed.\n",
      "Iteration 4 completed.\n",
      "Iteration 5 completed.\n",
      "Iteration 6 completed.\n",
      "Iteration 7 completed.\n",
      "Iteration 8 completed.\n",
      "Iteration 9 completed.\n",
      "Iteration 10 completed.\n",
      "Iteration 11 completed.\n",
      "Iteration 12 completed.\n",
      "Iteration 13 completed.\n",
      "Iteration 14 completed.\n",
      "Iteration 15 completed.\n",
      "Iteration 16 completed.\n",
      "Iteration 17 completed.\n",
      "Iteration 18 completed.\n",
      "Iteration 19 completed.\n",
      "Iteration 20 completed.\n",
      "Iteration 21 completed.\n",
      "Iteration 22 completed.\n",
      "Iteration 23 completed.\n",
      "Iteration 24 completed.\n",
      "Iteration 25 completed.\n",
      "Iteration 26 completed.\n",
      "Iteration 27 completed.\n",
      "Iteration 28 completed.\n",
      "Iteration 29 completed.\n",
      "Iteration 30 completed.\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(30):\n",
    "    test_indices = []\n",
    "    train_indices = []\n",
    "\n",
    "        \n",
    "    array1 = model_df['prb_id'].unique()\n",
    "    array2 = model_df['dst_id'].unique()\n",
    "\n",
    "    # Creating all possible pairs\n",
    "    pairs = list(itertools.product(array1, array2))\n",
    "\n",
    "    # Randomly selecting 10 pairs\n",
    "    selected_pairs = random.sample(pairs, 10)\n",
    "\n",
    "    # Removing selected pairs from the original list\n",
    "    for pair in selected_pairs:\n",
    "        pairs.remove(pair)\n",
    "\n",
    "    # Creating separate lists\n",
    "    selected_list = selected_pairs\n",
    "    remaining_list = pairs\n",
    "\n",
    "    train_dfs = []\n",
    "    for i,k in remaining_list:\n",
    "        temp_df = model_df.loc[(model_df['prb_id'] == i) & (model_df['dst_id'] == k)]\n",
    "                \n",
    "        # Append the piece to the selected data\n",
    "        train_dfs.append(temp_df)\n",
    "                \n",
    "        train_df = pd.concat(train_dfs)\n",
    "            \n",
    "    test_dfs = []\n",
    "    for i,k in selected_list:\n",
    "        temp_df = model_df.loc[(model_df['prb_id'] == i) & (model_df['dst_id'] == k)]\n",
    "                \n",
    "        # Append the piece to the selected data\n",
    "        test_dfs.append(temp_df)\n",
    "\n",
    "        test_df = pd.concat(train_dfs)\n",
    "        \n",
    "    \n",
    "    trainrtt_mean = train_df['last_rtt'].mean()\n",
    "    trainrtt_std = train_df['last_rtt'].std()\n",
    "    \n",
    "    traindist_mean = train_df['distance'].mean()\n",
    "    traindist_std = train_df['distance'].std()\n",
    "    \n",
    "    # normalizing rtt values for train_df\n",
    "    train_df['normalizzed_rtt'] = (train_df['last_rtt'] - trainrtt_mean) / trainrtt_std\n",
    "    train_df['normalizzed_distance'] = (train_df['distance'] - traindist_mean) / traindist_std\n",
    "    \n",
    "    # normalizing rtt values for test_df\n",
    "    test_df['normalizzed_rtt'] = (test_df['last_rtt'] - trainrtt_mean) / trainrtt_std\n",
    "    test_df['normalizzed_distance'] = (test_df['distance'] - traindist_mean) / traindist_std\n",
    "\n",
    "    # Pickle the train and test dataframes in the 'pickles' folder\n",
    "    train_df.to_pickle(os.path.join('train_test_pickles', f'train_df_{iteration}.pickle'))\n",
    "    test_df.to_pickle(os.path.join('train_test_pickles', f'test_df_{iteration}.pickle'))\n",
    "\n",
    "    print(f'Iteration {iteration + 1} completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder named 'model_results' (you can change the folder name as needed)\n",
    "results_folder = 'model_results'\n",
    "os.makedirs(results_folder, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
